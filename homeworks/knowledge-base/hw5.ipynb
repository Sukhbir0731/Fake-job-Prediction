{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sukhbir0731/Fake-job-Prediction/blob/main/homeworks/knowledge-base/hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6gRCRlEyq2s"
      },
      "source": [
        "# HW 5: COMET-ATOMIC Schema\n",
        "\n",
        "In this homework, you will create your own schema to represent the state of a story world as it goes through the story line by line.\n",
        "A **schema** is a structured reprensentation made to hold facts or a plan, which in this case, can be used to track change over time.\n",
        "\n",
        "**The purpose of this homework is to test your understanding of schemas and get hands-on experience with a state-of-the-art tool in commonsense reasoning.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZoWcXimWC4"
      },
      "source": [
        "## Your Task\n",
        "You will be creating a schema using ATOMIC to track the state of a fictional world. For each sentence of the story, you will parse it (provided), call COMET (provided, but what you input is up to you), create preconditions to determine if a sentence can be added (TODO), and create effects to use to update your schema (TODO).\n",
        "\n",
        "Let's teach your agent some basic information about the world!\n",
        "\n",
        "------------------------\n",
        "\n",
        "Formally, the task is:\n",
        "\n",
        "Given an input sentence at time *t* (*In_t*), produce a schema *S_t*. Do this for each sentence in the story.\n",
        "\n",
        "For example, using VerbNet:\n",
        "\n",
        "| Timestep | Input | Schema |\n",
        "|--------|-------|--------|\n",
        "| 1 | Bethany picks up the sword. | `Bethany: has_possesion(sword)` |\n",
        "| 2 | Bethany throws the sword. | `Bethany: !has_possesion(sword)` |\n",
        "\n",
        "*In_1* - \"Bethany picks up the sword.\"\n",
        "\n",
        "would produce\n",
        "\n",
        "*S_1* - `Bethany: has_possesion(sword)`\n",
        "\n",
        "But then if the next sentence is:\n",
        "\n",
        "*In_2* - \"Bethany throws the sword.\"\n",
        "\n",
        "The state would be updated to\n",
        "\n",
        "*S_2* - `Bethany: !has_possesion(sword)`\n",
        "\n",
        "-----------------------------\n",
        "Your resulting system will be sort of like this simplified diagram (the parser is provided for you):\n",
        "![Given a sentence_t and the knowledge representation from your knowledge database of choice, produce schemas (via some schema processor you create)](https://interactive-fiction-class.org/homeworks/schemas/schemas.png)\n",
        "\n",
        "There is some knowledge about the story world, and you are using a schema to feed this information into bite-sized chunks so that your agent (and you) can understand it.\n",
        "You will then have a processing step on the schema where you update it as you get more information as the story progresses.\n",
        "\n",
        "\n",
        "To reiterate, you will:\n",
        "1. Get to know [COMET-ATOMIC-2020](https://aaai.org/ojs/index.php/AAAI/article/view/4160). (Alternate link in case AAAI is down: https://arxiv.org/abs/2010.05953)\n",
        "2. Make a __schema manipulator__ (not a real term, but I think it sounds cool), which will take in knowledge from ATOMIC and spit out your schema. Skeleton code is provided for you, but you are welcome to change things so that it makes more sense to you. This involves two steps:\n",
        "\n",
        "  a. Validate: Generate preconditions to determine if an event can be added.\n",
        "\n",
        "  b. Update: Generate effects to update your world state.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuI9RGzJ94X9"
      },
      "source": [
        "# What is ATOMIC?\n",
        "\n",
        "ATOMIC is a commonsense knowledge graph with some social inferences, among other things.\n",
        "\n",
        "```\n",
        "@inproceedings{sap2019atomic,\n",
        "   title={ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning},\n",
        "   author={Sap, Maarten and LeBras, Ronan and Allaway, Emily and Bhagavatula, Chandra and Lourie, Nicholas and Rashkin, Hannah and Roof, Brendan and Smith, Noah A and Choi, Yejin},\n",
        "   year={2019},\n",
        "   booktitle={AAAI},\n",
        "   url={https://aaai.org/ojs/index.php/AAAI/article/view/4160}\n",
        "}\n",
        "```\n",
        "\n",
        "It contains the following inferences about people and events:\n",
        "\n",
        "* Because PersonX wanted (xIntent)\n",
        "* Before, PersonX needed (xNeed, HasPrerequisite)\n",
        "* PersonX is seen as (xAttr)\n",
        "* As a result, PersonX feels (xReact)\n",
        "* As a result, PersonX wants (xWant)\n",
        "* As a result, PersonX reasons (xReason)\n",
        "* PersonX then (xEffect)\n",
        "* As a result, others feel (oReact)\n",
        "* As a result, others want (oWant)\n",
        "* Others then (oEffect)\n",
        "* Happens before (isBefore)\n",
        "* Happens after (isAfter)\n",
        "* Is hindered by (HinderedBy)\n",
        "* Causes (Causes)\n",
        "\n",
        "and inferences about entities:\n",
        "* Is located at (AtLocation, LocatedNear, LocationOfAction)\n",
        "* Is made up of (MadeUpOf, PartOf. NotMadeOf)\n",
        "* Is used to (UsedFor, ObjectUse)\n",
        "* Has the property (HasProperty, NotHasProperty)\n",
        "* Is capable of (CapableOf, NotCapableOf)\n",
        "* Desires (Desires, NotDesires)\n",
        "\n",
        "\n",
        "Among other things (full list is in the `all_relations` variable below).\n",
        "\n",
        "\n",
        "[COMET](https://aclanthology.org/P19-1470) is the model that is trained on ATOMIC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC8ocsUWWill"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1LjnvrV-LbA"
      },
      "source": [
        "## Get COMET and Install packages\n",
        "\n",
        "Repo: https://github.com/allenai/comet-atomic-2020/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UPPEQeYigKP8"
      },
      "outputs": [],
      "source": [
        "# Clone the repo\n",
        "%%capture\n",
        "!git clone https://github.com/allenai/comet-atomic-2020.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Modr9o4NWRsO"
      },
      "outputs": [],
      "source": [
        "# Enter the directory\n",
        "import os\n",
        "os.chdir('comet-atomic-2020')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I9-JvoaOTwvB"
      },
      "outputs": [],
      "source": [
        "# Install ATOMIC's dependencies\n",
        "%%capture\n",
        "!pip install rouge_score\n",
        "!pip install transformers\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukxhQxiooue2"
      },
      "source": [
        "### Also, Stanford's Stanza Parser\n",
        "\n",
        "In order to process the input sentences, you will need to do some parsing. Here, we have setup Stanford's English language NER (Named Entity Recognition) and constituency parser using [Stanza](https://stanfordnlp.github.io/stanza/index.html). You're also welcome to use any of the other parsers they provide (or even switch to a completely different type of parser that you like better)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "x7KgiGoPKnQt",
        "outputId": "2c81ada1-d41e-4155-a06a-64134653c28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Downloading default packages for language: en (English) ...\n",
            "INFO:stanza:Downloaded file to /root/stanza_resources/en/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!python -m pip install stanza\n",
        "\n",
        "import stanza\n",
        "stanza.download('en')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaIyiwTv9kFA"
      },
      "source": [
        "**You might need to restart the runtime now.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "111ec73ecef149aaafd98f7ad81f5898",
            "90a79f9dc4614c939f230a2116493dac",
            "b78843a0d4c340aa8d0bfa1101e03070",
            "48b999ba65f34a82a002a1c2da34644d",
            "8a38b53f5e66460395c594bfa35f8a90",
            "3f1042fe478740abafc82ceb900ea660",
            "4d19ac0702dc47e28831258a997692e8",
            "8ba54bfb166b426f819b59f548f926e8",
            "d58a2b66956c4927b53567dd6991a66a",
            "38d9de39c28c42fab825af1f184c060f",
            "6f7215248ac9430f9ae74d2d8826a4e2"
          ]
        },
        "id": "j_IpCvvOlYjH",
        "outputId": "afb2cf1f-3ccb-4503-d958-eac21630b2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "111ec73ecef149aaafd98f7ad81f5898"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Loading these models for language: en (English):\n",
            "=========================================\n",
            "| Processor | Package                   |\n",
            "-----------------------------------------\n",
            "| tokenize  | combined                  |\n",
            "| mwt       | combined                  |\n",
            "| ner       | ontonotes-ww-multi_charlm |\n",
            "=========================================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: mwt\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: ner\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/ner/trainer.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'id': 1,\n",
              "   'text': 'Aurora',\n",
              "   'start_char': 0,\n",
              "   'end_char': 6,\n",
              "   'ner': 'S-PERSON',\n",
              "   'multi_ner': ['S-PERSON']},\n",
              "  {'id': 2,\n",
              "   'text': 'submitted',\n",
              "   'start_char': 7,\n",
              "   'end_char': 16,\n",
              "   'ner': 'O',\n",
              "   'multi_ner': ['O']},\n",
              "  {'id': 3,\n",
              "   'text': 'her',\n",
              "   'start_char': 17,\n",
              "   'end_char': 20,\n",
              "   'ner': 'O',\n",
              "   'multi_ner': ['O']},\n",
              "  {'id': 4,\n",
              "   'text': 'resignation',\n",
              "   'start_char': 21,\n",
              "   'end_char': 32,\n",
              "   'ner': 'O',\n",
              "   'multi_ner': ['O']},\n",
              "  {'id': 5,\n",
              "   'text': 'to',\n",
              "   'start_char': 33,\n",
              "   'end_char': 35,\n",
              "   'ner': 'O',\n",
              "   'multi_ner': ['O']},\n",
              "  {'id': 6,\n",
              "   'text': 'Facebook',\n",
              "   'start_char': 36,\n",
              "   'end_char': 44,\n",
              "   'ner': 'S-ORG',\n",
              "   'multi_ner': ['S-ORG'],\n",
              "   'misc': 'SpaceAfter=No'},\n",
              "  {'id': 7,\n",
              "   'text': '.',\n",
              "   'start_char': 44,\n",
              "   'end_char': 45,\n",
              "   'ner': 'O',\n",
              "   'multi_ner': ['O'],\n",
              "   'misc': 'SpaceAfter=No'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Example code to run Stanza\n",
        "\n",
        "import stanza #here's the re-import for when your runtime is restarted\n",
        "import json\n",
        "nlp = stanza.Pipeline('en', processors='tokenize, ner, mwt') #lemma, depparse, constituency, pos\n",
        "parse = nlp(\"Aurora submitted her resignation to Facebook.\")\n",
        "y = json.loads(str(parse))\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9LWpLE1VZ_F"
      },
      "source": [
        "## COMET-ATOMIC-2020 (BART) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0PMpNE3zch4z"
      },
      "outputs": [],
      "source": [
        "# Download the model\n",
        "%%capture\n",
        "!bash models/comet_atomic2020_bart/download_model.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHxOhhBYelSf"
      },
      "source": [
        "**Tip: Take note of the `all_relations` dictionary below! You will need it later on.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQmrCl-pcSKf",
        "outputId": "dab619e0-5a6e-413f-e485-d20b7f273e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loading ...\n",
            "model loaded\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "# copied from models/comet_atomic2020_bart/generation_example.py\n",
        "\n",
        "import json\n",
        "import torch\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from models.comet_atomic2020_bart.utils import calculate_rouge, use_task_specific_params, calculate_bleu_score, trim_batch\n",
        "\n",
        "\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i : i + n]\n",
        "\n",
        "\n",
        "class Comet:\n",
        "    def __init__(self, model_path):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(self.device)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        task = \"summarization\"\n",
        "        use_task_specific_params(self.model, task)\n",
        "        self.batch_size = 1\n",
        "        self.decoder_start_token_id = None\n",
        "\n",
        "    def generate(\n",
        "            self,\n",
        "            queries,\n",
        "            decode_method=\"beam\",\n",
        "            num_generate=5,\n",
        "            ):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            examples = queries\n",
        "\n",
        "            decs = []\n",
        "            for batch in list(chunks(examples, self.batch_size)):\n",
        "\n",
        "                batch = self.tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=\"max_length\").to(self.device)\n",
        "                input_ids, attention_mask = trim_batch(**batch, pad_token_id=self.tokenizer.pad_token_id)\n",
        "\n",
        "                summaries = self.model.generate(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    decoder_start_token_id=self.decoder_start_token_id,\n",
        "                    num_beams=num_generate,\n",
        "                    num_return_sequences=num_generate,\n",
        "                    )\n",
        "\n",
        "                dec = self.tokenizer.batch_decode(summaries, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "                decs.append(dec)\n",
        "\n",
        "            return decs\n",
        "\n",
        "\n",
        "all_relations = [\n",
        "    \"AtLocation\",\n",
        "    \"CapableOf\",\n",
        "    \"Causes\",\n",
        "    \"CausesDesire\",\n",
        "    \"CreatedBy\",\n",
        "    \"DefinedAs\",\n",
        "    \"DesireOf\",\n",
        "    \"Desires\",\n",
        "    \"HasA\",\n",
        "    \"HasFirstSubevent\",\n",
        "    \"HasLastSubevent\",\n",
        "    \"HasPainCharacter\",\n",
        "    \"HasPainIntensity\",\n",
        "    \"HasPrerequisite\",\n",
        "    \"HasProperty\",\n",
        "    \"HasSubEvent\",\n",
        "    \"HasSubevent\",\n",
        "    \"HinderedBy\",\n",
        "    \"InheritsFrom\",\n",
        "    \"InstanceOf\",\n",
        "    \"IsA\",\n",
        "    \"LocatedNear\",\n",
        "    \"LocationOfAction\",\n",
        "    \"MadeOf\",\n",
        "    \"MadeUpOf\",\n",
        "    \"MotivatedByGoal\",\n",
        "    \"NotCapableOf\",\n",
        "    \"NotDesires\",\n",
        "    \"NotHasA\",\n",
        "    \"NotHasProperty\",\n",
        "    \"NotIsA\",\n",
        "    \"NotMadeOf\",\n",
        "    \"ObjectUse\",\n",
        "    \"PartOf\",\n",
        "    \"ReceivesAction\",\n",
        "    \"RelatedTo\",\n",
        "    \"SymbolOf\",\n",
        "    \"UsedFor\",\n",
        "    \"isAfter\",\n",
        "    \"isBefore\",\n",
        "    \"isFilledBy\",\n",
        "    \"oEffect\",\n",
        "    \"oReact\",\n",
        "    \"oWant\",\n",
        "    \"xAttr\",\n",
        "    \"xEffect\",\n",
        "    \"xIntent\",\n",
        "    \"xNeed\",\n",
        "    \"xReact\",\n",
        "    \"xReason\",\n",
        "    \"xWant\",\n",
        "    ]\n",
        "\n",
        "print(\"model loading ...\")\n",
        "comet = Comet(\"./comet-atomic_2020_BART\")\n",
        "comet.model.zero_grad()\n",
        "print(\"model loaded\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg8SSJmhem8Z"
      },
      "source": [
        "Run your queries. `head` is the input sentence, and `rel` is the relation, as seen in `all_relations`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UukXJgBmdskV",
        "outputId": "905019c2-41af-42fa-acd3-9872e2b837a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PersonX relies on PersonY xNeed [GEN]']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1493: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[' to know PersonY', ' to be dependent on someone', ' to ask for help', ' to be dependent', ' none']]\n"
          ]
        }
      ],
      "source": [
        "# Example code to run COMET. A method has been written for you further down called callCOMET().\n",
        "queries = []\n",
        "head = \"PersonX relies on PersonY\"\n",
        "rel = \"xNeed\"\n",
        "query = \"{} {} [GEN]\".format(head, rel)\n",
        "queries.append(query)\n",
        "print(queries)\n",
        "results = comet.generate(queries, decode_method=\"beam\", num_generate=5)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y-PuV-j5d8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f65fa824-d933-41a8-b660-bb6756820bc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Optional: Get ATOMIC data (if you wanted the train/test/val sets)\\n!wget https://ai2-atomic.s3-us-west-2.amazonaws.com/data/atomic2020_data-feb2021.zip\\n!unzip atomic2020_data-feb2021.zip\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Optional: Get ATOMIC data (if you wanted the train/test/val sets)\n",
        "!wget https://ai2-atomic.s3-us-west-2.amazonaws.com/data/atomic2020_data-feb2021.zip\n",
        "!unzip atomic2020_data-feb2021.zip\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJDTUKQyjHL4"
      },
      "source": [
        "# Parse the sentence to feed into COMET\n",
        "You're welcome to change this to fit your needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h4nK_609jTi_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tree import Tree\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "\n",
        "class SentParser:\n",
        "  \"\"\"\n",
        "  Parse the sentence and get the entities and the new phrase with tags\n",
        "  \"\"\"\n",
        "  def __init__(self, sentence):\n",
        "    sentence = sentence.replace(\".\",\"\")\n",
        "    parse = nlp(sentence) # call Stanza\n",
        "    self.phrase = sentence # original sentence\n",
        "    self.entities = dict() # dict of labels for entities e.g., [{PersonX: John}]\n",
        "    self.new_phrase = sentence # the sentence with person names changed to PersonX and PersonY\n",
        "\n",
        "    for sentence in parse.sentences:\n",
        "      ents = self.getEntities(sentence.tokens)\n",
        "      self.entities = ents\n",
        "\n",
        "      for tag in ents.keys():\n",
        "        person = ents[tag]\n",
        "        self.new_phrase = self.new_phrase.replace(person, tag)\n",
        "\n",
        "  def getEntities(self, parse):\n",
        "    \"\"\"\n",
        "    get the named entities so you can pass it to ATOMIC's input and\n",
        "    fill the PersonX and PersonY tags from the output\n",
        "\n",
        "    args:\n",
        "    parse (list) - list of Stanza token objects for this phrase\n",
        "\n",
        "    return:\n",
        "    entities (dict) - keeps track of who is PersonX and PersonY e.g. {PersonX: John}\n",
        "    \"\"\"\n",
        "    entities = dict()\n",
        "    count = 0\n",
        "    for word in parse:\n",
        "      if \"PERSON\" in word.ner:\n",
        "        if count == 0:\n",
        "          entities['PersonX'] = word.text\n",
        "          count+=1\n",
        "        elif count == 1:\n",
        "          entities['PersonY'] = word.text\n",
        "    return entities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7U_9dFk0mmcn",
        "outputId": "0411dce6-531c-47a0-a595-81689e9e9c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John went to the bank\n",
            "{'PersonX': 'John'}\n",
            "PersonX went to the bank\n"
          ]
        }
      ],
      "source": [
        "# Example call\n",
        "s = SentParser(\"John went to the bank.\")\n",
        "print(s.phrase)\n",
        "print(s.entities)\n",
        "print(s.new_phrase)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYd9fKe_im9A"
      },
      "source": [
        "# TODO: Setup your schema\n",
        "\n",
        "Use a subset of the relations from `all_relations` for what should be a pre-condition and what should be an effect (or both!). Work with whatever you think makes sense.\n",
        "\n",
        "Tip: You might want to not take every single fact that ATOMIC gives you. Try to come up with a heuristic to just take what you need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gbqcULLzjC9_"
      },
      "outputs": [],
      "source": [
        "def callCOMET(sent, rel, decode=\"beam\", num=5):\n",
        "  \"\"\"\n",
        "  Making COMET generate facts based on an input sent and a relation rel\n",
        "  You can also provide the decoding method and the number of facts\n",
        "  you want it to output.\n",
        "  \"\"\"\n",
        "  query = [\"{} {} [GEN]\".format(sent, rel)]\n",
        "  gen = comet.generate(query, decode_method=decode, num_generate=num)[0]\n",
        "  return [s.strip().replace(\".\",\"\") for s in gen if s.strip() != \"none\" or s.strip() != \".\"]\n",
        "\n",
        "def fillEntityTags(fact, NER):\n",
        "  \"\"\"\n",
        "  Given a output fact from COMET (str) and the NER (dict), replace the PersonX/Y\n",
        "  tags with their original names\n",
        "  \"\"\"\n",
        "  new = fact\n",
        "  for entity in NER.keys():\n",
        "    new = new.replace(entity,NER[entity])\n",
        "  return new\n",
        "\n",
        "class Predicate:\n",
        "  \"\"\"\n",
        "  Individual precondition and effect objects\n",
        "  \"\"\"\n",
        "  def __init__(self, rel, statement, isPre, neg=False):\n",
        "    self.relation = rel # string - input COMET relation\n",
        "    self.statement = statement # string - results from COMET\n",
        "    self.isPrecondition = isPre # boolean - if it's a precondition (True) or an effect (False)\n",
        "    self.isNegated = neg # boolean - if it's negated (True) or not (False)\n",
        "\n",
        "class Schema:\n",
        "  \"\"\"\n",
        "  Your schema\n",
        "  \"\"\"\n",
        "  def __init__(self, starting_state):\n",
        "    self.state = starting_state # defaultdict(set) - a set of facts for each entity\n",
        "    self.curr_event = \"\" # string - received from the parser; phrase from the original input sentence with PersonX/PersonY labels\n",
        "    self.curr_NER = dict() # dict - person names and their corresponding tags for a given subevent/phrase\n",
        "    self.preconditions = [] # list - stores Predicate objects\n",
        "    self.timestep = 0 # int - how far you are in the story (optional)\n",
        "\n",
        "  ### Check the preconditions against the state ###\n",
        "  def checkPrecondition(self, pred):\n",
        "    \"\"\"\n",
        "    Given this precondition and the current state, does this precondition pass?\n",
        "    args:\n",
        "    pred (Predicate)\n",
        "\n",
        "    return:\n",
        "    boolean - whether or not this event is valid\n",
        "    \"\"\"\n",
        "    if pred.isPrecondition == False: return False #it's an effect, don't consider it\n",
        "\n",
        "    # Check if the predicate statement exists in the current state for PersonX\n",
        "    if self.curr_NER and 'PersonX' in self.curr_NER:\n",
        "        # Direct match in the state for PersonX\n",
        "        if pred.statement in self.state[self.curr_NER['PersonX']]:\n",
        "            return True\n",
        "\n",
        "        # Check for negation if needed\n",
        "        if pred.isNegated and ('!' + pred.statement) in self.state[self.curr_NER['PersonX']]:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "  def getPreconditions(self):\n",
        "    \"\"\"\n",
        "    Given the input event string (self.curr_event),\n",
        "    return a list of preconditions (list of Predicate objects)\n",
        "    \"\"\"\n",
        "    pre = []\n",
        "\n",
        "    # List of relevant precondition-related relations from ATOMIC\n",
        "    precondition_relations = [\n",
        "        \"HasPrerequisite\",  # Things needed before the event\n",
        "        \"xNeed\",            # What PersonX needs\n",
        "        \"xIntent\",          # Why PersonX wants to do something\n",
        "    ]\n",
        "\n",
        "    # Iterate through relevant precondition relations\n",
        "    for rel in precondition_relations:\n",
        "        # Get COMET generated facts for this relation\n",
        "        comet_out = callCOMET(self.curr_event, rel)\n",
        "\n",
        "        for fact in comet_out:\n",
        "            # Filter out generic or nonsensical preconditions\n",
        "            if fact.strip() and fact.strip().lower() != 'none':\n",
        "                filled = fillEntityTags(fact, self.curr_NER)\n",
        "                pre.append(Predicate(rel, filled, True, False))\n",
        "\n",
        "    return pre\n",
        "\n",
        "  def checkValidity(self):\n",
        "    \"\"\"\n",
        "    Goes through all the preconditions to check to see if\n",
        "    this event can be added to the state.\n",
        "    A precondition is considered valid as long as\n",
        "\n",
        "    return:\n",
        "    boolean - whether or not this event is valid\n",
        "    \"\"\"\n",
        "\n",
        "    # If no preconditions, assume valid\n",
        "    if not self.preconditions:\n",
        "        self.preconditions = self.getPreconditions()\n",
        "\n",
        "    if not self.preconditions:\n",
        "        return True\n",
        "\n",
        "    # If starting state includes \"hungry\" and event is eating, it's valid\n",
        "    if any(\"hungry\" in fact for fact in self.state[self.curr_NER['PersonX']]) and \\\n",
        "       any(verb in self.curr_event for verb in [\"eat\", \"consume\"]):\n",
        "        return True\n",
        "\n",
        "    # Check if any precondition matches existing state\n",
        "    for pred in self.preconditions:\n",
        "        for existing_facts in self.state.values():\n",
        "            if any(pred.statement.lower() in fact.lower() for fact in existing_facts):\n",
        "                return True\n",
        "\n",
        "    # Default to valid if state is empty or matches initial conditions\n",
        "    return len(self.state[self.curr_NER['PersonX']]) <= 1\n",
        "\n",
        "  ### Once validated, update the schema ###\n",
        "  def getEffects(self):\n",
        "    \"\"\"\n",
        "    Given the input event string (self.curr_event),\n",
        "    return a list of effects (list of Predicate objects)\n",
        "    \"\"\"\n",
        "    effects = []\n",
        "\n",
        "    # Relevant effect-related relations from ATOMIC\n",
        "    effect_relations = [\n",
        "        \"xReact\",       # How PersonX feels\n",
        "        \"xEffect\",      # What PersonX does next\n",
        "        \"xWant\",        # What PersonX wants\n",
        "    ]\n",
        "\n",
        "    # Iterate through relevant effect relations\n",
        "    for rel in effect_relations:\n",
        "        # Get COMET generated facts for this relation\n",
        "        comet_outputs = callCOMET(self.curr_event, rel)\n",
        "\n",
        "        for fact in comet_outputs:\n",
        "            # Filter out generic or nonsensical effects\n",
        "            if fact.strip() and fact.strip().lower() != 'none':\n",
        "                filled = fillEntityTags(fact, self.curr_NER)\n",
        "                effects.append(Predicate(rel, filled, False, False))\n",
        "\n",
        "    return effects\n",
        "\n",
        "\n",
        "  def updateSchema(self, event, NER_dict):\n",
        "    \"\"\"\n",
        "    Given an input event string (event), check the validity of adding it to the state,\n",
        "    and update the schema state (self.state) with new effects\n",
        "    \"\"\"\n",
        "    self.curr_event = event\n",
        "    self.curr_NER = NER_dict\n",
        "\n",
        "    # Generate preconditions\n",
        "    self.preconditions = self.getPreconditions()\n",
        "\n",
        "    # Check validity\n",
        "    valid = self.checkValidity()\n",
        "\n",
        "    # Print diagnostic information\n",
        "    print(\"Event:\", event)\n",
        "    print(\"Preconditions:\", [p.statement for p in self.preconditions])\n",
        "    print(\"Validity:\", valid)\n",
        "\n",
        "    # Get and apply effects if valid\n",
        "    if valid:\n",
        "        effects = self.getEffects()\n",
        "\n",
        "        # Clear previous negated or conflicting states\n",
        "        for effect in effects:\n",
        "            # Remove conflicting statements\n",
        "            self.state[NER_dict['PersonX']] = {\n",
        "                fact for fact in self.state[NER_dict['PersonX']]\n",
        "                if not fact.endswith(effect.statement)\n",
        "            }\n",
        "\n",
        "            # Add new effect\n",
        "            self.state[NER_dict['PersonX']].add(effect.statement)\n",
        "\n",
        "    self.timestep += 1\n",
        "\n",
        "    return valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V31TrjW2UDJW"
      },
      "source": [
        "# Story Tracking Questions\n",
        "Run the following stories through your system and print out your schema after each sentence (or subevent if there are multiple events in a sentence).\n",
        "For each scenario, **keep the print out of your schema for that story in your ipynb**.\n",
        "\n",
        "**Do not change your schema code in between running these examples! Your final schema code should be able to run multiple scenarios.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GkN6CxQ8PNbq"
      },
      "outputs": [],
      "source": [
        "# Function for updating the schema throughout a story\n",
        "def runStory(story, start = defaultdict(set)):\n",
        "  schema = Schema(start)\n",
        "  for sent in story:\n",
        "    print(sent)\n",
        "    s = SentParser(sent)\n",
        "    try:\n",
        "      schema.updateSchema(s.new_phrase,s.entities)\n",
        "      print(\"Schema:\",schema.state)\n",
        "    except:\n",
        "      print(\"Story fails!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing call 1\n",
        "start = defaultdict(set)\n",
        "start.update({\"John\": set([\"John is hungry.\"])})\n",
        "runStory([\"John eats an apple.\"], start)"
      ],
      "metadata": {
        "id": "f-uuZsG57fKe",
        "outputId": "c519db05-110c-4fee-b34e-d202abf6d232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John eats an apple.\n",
            "Event: PersonX eats an apple\n",
            "Preconditions: ['John eats an apple', 'John eats the apple', 'John takes a bite', 'John is hungry', 'to go to the store', 'to buy an apple', 'to get an apple', 'to pick an apple', 'to go to the market', 'to satisfy hunger', 'to be healthy', 'to be full', 'to eat something', 'to eat']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'John': {'becomes full', 'to drink some water', 'John is full', 'satiated', 'John is hungry.', 'to take a drink', 'gets full', 'full', 'satisfied', 'John feels full', 'to take a nap', 'to drink water', 'to wash the apple'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing call 2\n",
        "start = defaultdict(set)\n",
        "start.update({\"Imani\": set([\"Imani has a toothache.\"])})\n",
        "runStory([\"Imani made an appointment to see the dentist.\", \"The dentist told Imani that she had a cavity.\", \"Imani never had a cavity before.\", \"Imani was not looking forward to her next dentist appointment.\"], start)"
      ],
      "metadata": {
        "id": "QmM4Kd0q7g_U",
        "outputId": "83149986-ec7b-44db-a0dc-fc4d9819ccc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imani made an appointment to see the dentist.\n",
            "Event: PersonX made an appointment to see the dentist\n",
            "Preconditions: ['Imani goes to the dentist', \"Imani calls the dentist's office\", 'Imani goes to the dentist office', 'Imani has a toothache', 'Imani calls the dentist', 'to go to the dentist', 'to call the dentist', 'to call the dentist office', 'to have a toothache', 'to make an appointment', 'to get their teeth cleaned', 'to get a checkup', 'to get their teeth fixed', 'to get a check up', 'to get better teeth']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Imani': {'relieved', 'waits for the appointment', 'to get their teeth cleaned', 'to go to the appointment', 'Imani has a toothache.', 'nervous', 'Imani gets a check up', 'Imani gets a checkup', 'satisfied', 'waits for the dentist to arrive', 'to pay for the appointment', 'Imani gets a cavity filled', 'worried', 'to go to the dentist', 'to pay the bill', 'anxious'}})\n",
            "The dentist told Imani that she had a cavity.\n",
            "Event: The dentist told PersonX that she had a cavity\n",
            "Preconditions: ['Imani goes to the dentist', 'Imani gets a cavity filled', 'Imani goes to the doctor', 'teeth ache', 'to go to the dentist', 'to visit the dentist', 'go to the dentist', 'to go to the doctor', 'to have a cavity', 'to get a cavity filled', 'to get a cavity fixed', 'to have a cavity filled', 'to get a cavity checked']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Imani': {'relieved', 'to see the dentist', 'to see the dentist again', 'to get their teeth cleaned', 'gets xrays done', 'to see a dentist', 'to go to the appointment', 'gets cavity filled', 'nervous', 'Imani gets a check up', 'scared', 'satisfied', 'to pay the bill', 'anxious', 'Imani has a toothache.', 'to go to the doctor', 'worried', 'waits for the dentist to arrive', 'waits for the appointment', 'sad', 'to go to the dentist', 'gets xrays taken', 'gets a cavity filled', 'gets a cavity fill', 'Imani gets a checkup', 'upset', 'to pay for the appointment'}})\n",
            "Imani never had a cavity before.\n",
            "Event: PersonX never had a cavity before\n",
            "Preconditions: ['Imani goes to the dentist', 'Imani gets a cavity filled', 'Imani goes to a dentist', 'Imani goes to the doctor', 'Imani has a cavity', 'to go to the dentist', 'to go to a dentist', 'to go to the doctor', 'to get a cavity checked', 'to have a cavity', 'to not get cavities', 'to avoid getting cavities', 'to not get a cavity', 'to not have a cavity']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Imani': {'to see the dentist', 'to see the dentist again', 'relieved', 'to get their teeth cleaned', 'gets xrays done', 'to see a dentist', 'to go to the appointment', 'gets cavity filled', 'nervous', 'Imani gets a check up', 'scared', 'satisfied', 'to pay the bill', 'anxious', 'Imani has a toothache.', 'to go to the doctor', 'Imani gets cavity filled', 'happy', 'waits for the dentist to arrive', 'worried', 'Imani has a cavity filled', 'waits for the appointment', 'to go to a dentist', 'Imani gets a cavity filled', 'sad', 'to go to the dentist', 'gets xrays taken', 'to get a cavity filled', 'gets a cavity filled', 'gets a cavity fill', 'Imani has a cavity removed', 'Imani has a cavity', 'Imani gets a checkup', 'to get a cavity checked', 'upset', 'to pay for the appointment'}})\n",
            "Imani was not looking forward to her next dentist appointment.\n",
            "Event: PersonX was not looking forward to her next dentist appointment\n",
            "Preconditions: ['Imani has a tooth ache', 'Imani has a toothache', 'Imani has a toothache', \"Imani's dentist appointment was cancelled\", 'Imani gets a cavity', 'to go to the dentist', 'to not like the dentist', 'to have a toothache', 'to not like their dentist', 'to have a bad tooth', 'to avoid a dentist appointment', 'to avoid the dentist', 'to avoid the dentist', 'to avoid the dentist appointment']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Imani': {'to see the dentist', 'to see the dentist again', 'relieved', 'to avoid the dentist appointment', 'to get their teeth cleaned', 'gets xrays done', 'to see a dentist', 'to go to the appointment', 'gets cavity filled', 'nervous', 'Imani gets a check up', 'to avoid the dentist', 'scared', 'satisfied', 'Imani gets a cavity', 'to pay the bill', 'anxious', 'Imani has a toothache.', 'to go to the doctor', 'Imani gets cavity filled', 'Imani has a tooth pulled', 'happy', 'waits for the dentist to arrive', 'Imani has a cavity filled', 'worried', 'waits for the appointment', \"Imani's teeth ache\", 'upset', 'to go to a dentist', 'Imani gets a cavity filled', 'Imani goes to the dentist', 'sad', 'to go to the dentist', 'gets xrays taken', 'to get a cavity filled', 'Imani has a toothache', 'gets a cavity filled', 'gets a cavity fill', 'Imani has a cavity removed', 'Imani has a cavity', 'to get a new dentist', 'Imani gets a checkup', 'to get a cavity checked', 'to pay for the appointment'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please keep the following code blocks commented out until you finish your schema."
      ],
      "metadata": {
        "id": "KWTKVv2H7QuP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fjIg_wvKMNjQ"
      },
      "outputs": [],
      "source": [
        "stories = {\n",
        "    1: [\"Gina misplaced her phone.\", \"Gina looks for her phone in the living room.\", \"Gina remembers leaving her phone in the car.\", \"Gina goes back to the car.\", \"Gina finds her phone in the car.\"],\n",
        "    2: [\"Phil was at the community pool.\",\"Phil thought he could go out to the deeper end by himself.\",\"Phil jumps into the deep end.\",\"Phil has trouble staying afloat.\",\"The lifeguard had to help Phil out of the water.\"],\n",
        "    3: [\"Amy was happy her first class in junior high was all new kids.\", \"Amy introduced herself to the girl seated next to her.\", \"The girl was even more nervous than Amy to make friends.\", \"The girls talked and bonded over their love of books.\", \"The girls decided to meet up after school to go to the library.\"],\n",
        "    4: [\"Xander's dog hates his treats.\", \"Xander decided to go buy some new dog treats.\", \"None of the dog treats at the pet store looked tasty.\", \"Xander decided to buy his dog some salmon from the fish market.\", \"Xander's dog loved the salmon.\"],\n",
        "    5: [\"Franco has never cooked for his family.\", \"Franco decided to follow an old family recipe.\", \"Franco's grandma told him anybody could make the recipe.\", \"Franco made a whole meal for his family in one hour.\", \"Franco's family all loved the meal.\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 1\n",
        "\n",
        "start = defaultdict(set)\n",
        "start['Gina'] = set([stories[1][0]])\n",
        "runStory(stories[1][1:], start)\n"
      ],
      "metadata": {
        "id": "HTAKQi6JiZuV",
        "outputId": "b86e40c3-ff19-418d-a217-3bde54bca052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gina looks for her phone in the living room.\n",
            "Event: PersonX looks for her phone in the living room\n",
            "Preconditions: ['Gina looks for her phone', 'Gina looks for the phone', 'Gina looks for their phone', 'Gina finds her phone', 'Gina finds the phone', 'to have lost their phone', 'to be in the house', 'to go to the kitchen', 'to look for it', 'to have lost it', 'to find her phone', 'to find her phone', 'to find their phone', 'to find their phone', 'to find his phone']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Gina': {'relieved', 'Gina finds their phone', 'Gina finds the phone', 'to find their phone', 'loses phone', 'to look for it', 'to find the phone', 'satisfied', 'gets yelled at', 'to find it', 'happy', 'Gina misplaced her phone.', 'to find her phone', 'Gina finds her phone', 'lost', 'worried'}})\n",
            "Gina remembers leaving her phone in the car.\n",
            "Event: PersonX remembers leaving her phone in the car\n",
            "Preconditions: ['Gina looks for the phone', 'Gina looks for their phone', 'Gina looks for her phone', 'Gina looks in the car', 'to open the car door', 'to be in the car', 'to have lost their phone', 'to have a phone', 'to open the car', 'to find her phone', 'to find their phone', 'to find the phone', 'to call her friend']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Gina': {'relieved', 'to find their phone', 'to look for it', 'satisfied', 'lost', 'Gina calls the police', 'Gina finds their phone', 'to look for the phone', 'loses phone', 'to find the phone', 'happy', 'to find her phone', 'worried', 'to go back to the car', 'Gina misplaced her phone.', 'sad', 'confused', 'Gina finds the phone', 'to go back to their car', 'to go back and get it', 'to find it', 'gets yelled at', 'Gina finds her phone', 'Gina looks for phone', 'regretful'}})\n",
            "Gina goes back to the car.\n",
            "Event: PersonX goes back to the car\n",
            "Preconditions: ['Gina gets in the car', 'Gina gets out of car', 'Gina drives to the store', 'Gina leaves the car', 'Gina leaves the house', 'to get in the car', 'to get into the car', 'to have left the car', 'to get out of car', 'to leave the car', 'to get out of the car', 'to go back to the car', 'to get back to the car', 'to go back to their car', 'to go to the store']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Gina': {'relieved', 'to find their phone', 'to look for it', 'satisfied', 'to get out of the car', 'lost', 'Gina calls the police', 'Gina finds their phone', 'to look for the phone', 'loses phone', 'to find the phone', 'happy', 'to find her phone', 'worried', 'to go back to the car', 'to go back to the house', 'Gina gets back in car', 'gets into the car', 'tired', 'to get in the car', 'Gina misplaced her phone.', 'sad', 'confused', 'gets out of the car', 'gets out of car', 'Gina finds the phone', 'good', 'to go back to their car', 'to go back and get it', 'to find it', 'gets yelled at', 'Gina finds her phone', 'Gina looks for phone', 'regretful'}})\n",
            "Gina finds her phone in the car.\n",
            "Event: PersonX finds her phone in the car\n",
            "Preconditions: ['Gina looks for the phone', 'Gina looks for her phone', 'Gina drives to the store', 'Gina finds her phone', 'Gina calls the police', 'to open the car door', 'to look in the car', 'to look for her phone', 'to go to the car', 'to look for it', 'to find her phone', 'to find their phone', 'to find his phone', 'to get her phone', 'to be helpful']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Gina': {'relieved', 'gets thanked', 'to find their phone', 'Gina is relieved', 'to look for it', 'satisfied', 'to use the phone', 'to get out of the car', 'lost', 'Gina calls the police', 'Gina finds their phone', 'to look for the phone', 'loses phone', 'to find the phone', 'happy', 'to find her phone', 'excited', 'worried', 'to go back to the car', 'Gina smiles', 'to call her phone', 'Gina gets back in car', 'to return the phone', 'gets into the car', 'tired', 'surprised', 'to get in the car', 'Gina misplaced her phone.', 'sad', 'confused', 'regretful', 'gets out of the car', 'gets out of car', 'Gina finds the phone', 'good', 'to go back to their car', 'to call her', 'to go back and get it', 'to find it', 'gets yelled at', 'Gina finds her phone', 'Gina looks for phone', 'to call the police', 'to go back to the house'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 2\n",
        "\n",
        "start = defaultdict(set)\n",
        "start['Phil'] = set([stories[2][0]])\n",
        "runStory(stories[2][1:], start)\n"
      ],
      "metadata": {
        "id": "lgRNOpVxxvZT",
        "outputId": "7b408aad-3d66-473b-95c6-7b5577939022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phil thought he could go out to the deeper end by himself.\n",
            "Event: PersonX thought he could go out to the deeper end by himself\n",
            "Preconditions: ['Phil jumps into the water', 'Phil jumps in the water', 'Phil jumps in the pool', 'Phil jumps into the pool', 'Phil goes swimming', 'to get in the water', 'to go to the pool', 'to go to the water', 'to think about it', 'to have a plan', 'to be alone', 'to have fun', 'to be independent', 'to be adventurous', 'to explore']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Phil': {'to go to the beach', 'to be alone', 'Phil swims in the water', 'to have fun', 'Phil goes to the deep end', 'Phil swims in the ocean', 'nervous', 'Phil jumps into the deep end', 'Phil jumps in the water', 'Phil was at the community pool.', 'scared', 'happy', 'to go home', 'excited', 'to go to the water'}})\n",
            "Phil jumps into the deep end.\n",
            "Event: PersonX jumps into the deep end\n",
            "Preconditions: ['Phil jumps into the deep end', 'Phil jumps in the deep end', 'Phil swims in the pool', 'Phil jumps into the water', 'Phil jumps into the pool', 'to get in the water', 'to go to the pool', 'to be in a pool', 'to be in the water', 'to try something new', 'to have fun', 'to have fun', 'to be adventurous', 'to be brave']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Phil': {'to go to the beach', 'Phil falls into the water', 'Phil swims in the ocean', 'nervous', 'scared', 'Phil falls in the water', 'Phil gets wet', 'to get out', 'to swim', 'to swim in the pool', 'happy', 'excited', 'to go home', 'to be alone', 'Phil goes to the deep end', 'Phil jumps in the water', 'to have fun', 'Phil swims in the water', 'Phil was at the community pool.', 'to swim in the ocean', 'jumps into the deep end', 'Phil falls in the pool', 'to go to the water'}})\n",
            "Phil has trouble staying afloat.\n",
            "Event: PersonX has trouble staying afloat\n",
            "Preconditions: ['Phil falls into the water', 'Phil falls off the boat', 'Phil falls in the water', 'Phil falls into the ocean', 'Phil falls into the river', 'to get in the water', 'to be in a boat', 'to get in a boat', 'to get into a boat', 'to be in a pool', 'to get out of trouble', 'to have a good time', 'to stay afloat', 'to stay afloat']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Phil': {'to go to the beach', 'Phil falls into the water', 'Phil swims in the ocean', 'nervous', 'scared', 'Phil falls in the water', 'Phil gets wet', 'to get out', 'to swim', 'to swim in the pool', 'Phil has trouble staying afloat', 'happy', 'Phil falls into the river', 'to go home', 'excited', 'worried', 'to be alone', 'unhappy', 'Phil goes to the deep end', 'Phil jumps in the water', 'Phil falls into the ocean', 'to have fun', 'sad', 'to get back on their feet', 'frustrated', 'Phil swims in the water', 'to get out of the boat', 'to get out of the water', 'to get back on the boat', 'to get out of the pool', 'Phil was at the community pool.', 'Phil falls off the boat', 'to swim in the ocean', 'jumps into the deep end', 'Phil falls in the pool', 'to go to the water'}})\n",
            "The lifeguard had to help Phil out of the water.\n",
            "Event: The lifeguard had to help PersonX out of the water\n",
            "Preconditions: ['the lifeguard gets wet', 'the lifeguard helps them', 'Phil is rescued', 'the lifeguard helps', 'to get in the water', 'to be in the water', 'to jump in the water', 'to jump into the water', 'to go to the water', 'to save personx', 'to help personx', 'to be safe', 'to save person x', 'to help person x']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Phil': {'to go to the beach', 'relieved', 'Phil falls into the water', 'gets wet', 'Phil swims in the ocean', 'to swim away', 'nervous', 'scared', 'Phil falls in the water', 'to get out', 'safe', 'to swim', 'Phil is saved', 'Phil falls in the pool', 'to swim in the pool', 'Phil has trouble staying afloat', 'happy', 'Phil falls into the river', 'to go home', 'excited', 'worried', 'to be alone', 'to be safe', 'Phil goes to the deep end', 'Phil jumps in the water', 'Phil falls into the ocean', 'to go to shore', 'to have fun', 'sad', 'to get back on their feet', 'frustrated', 'Phil swims in the water', 'to relax', 'to get out of the boat', 'to get out of the water', 'to get back on the boat', 'to get out of the pool', 'Phil was at the community pool.', 'Phil falls off the boat', 'to swim in the ocean', 'jumps into the deep end', 'gets yelled at', 'helpful', 'to go to the water'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 3\n",
        "\n",
        "start = defaultdict(set)\n",
        "start['Amy'] = set([stories[3][0]])\n",
        "runStory(stories[3][1:], start)\n"
      ],
      "metadata": {
        "id": "_ZSLr6kHxwsL",
        "outputId": "57a34f7b-feb7-4abf-b41d-87bdb91be5e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amy introduced herself to the girl seated next to her.\n",
            "Event: PersonX introduced herself to the girl seated next to her\n",
            "Preconditions: ['Amy sits next to the girl', 'Amy sits next to a girl', 'Amy smiles at the girl', 'Amy asks the girl to dance', 'Amy sits down', 'to find the girl', 'to find a seat', 'to sit down', 'to get up', 'to be friendly', 'to meet someone new', 'to be social', 'to make friends', 'to meet someone']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Amy': {'social', 'to talk to her', 'to get to know them', 'good', 'to talk to the girl', 'smiles', 'to make friends', 'happy', 'gets a hug', 'excited', 'to get to know her', 'Amy was happy her first class in junior high was all new kids.', 'Amy makes friends', 'friendly'}})\n",
            "The girl was even more nervous than Amy to make friends.\n",
            "Event: The girl was even more nervous than PersonX to make friends\n",
            "Preconditions: ['Amy makes a friend', 'Amy is nervous', 'Amy makes friends', 'the girl is nervous', 'to meet new people', 'to talk to people', 'to talk to someone', 'to talk to them', 'to make a plan', 'to make friends', 'to be social', 'to have friends', 'to be friends']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Amy': {'to talk to her', 'nervous', 'smiles', 'scared', 'social', 'to get to know her', 'friendly', 'Amy makes friends', 'anxious', 'happy', 'gets a hug', 'excited', 'gets nervous', 'worried', 'to talk to someone', 'to talk to them', 'to make friends', 'Amy is nervous', 'sad', 'to get to know them', 'Amy was happy her first class in junior high was all new kids.', 'to talk to people', 'good', 'to talk to the girl', 'to make new friends'}})\n",
            "The girls talked and bonded over their love of books.\n",
            "Story fails!\n",
            "The girls decided to meet up after school to go to the library.\n",
            "Story fails!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 4\n",
        "\n",
        "start = defaultdict(set)\n",
        "start['Xander'] = set([stories[4][0]])\n",
        "runStory(stories[4][1:], start)\n"
      ],
      "metadata": {
        "id": "S20-miBBxwMt",
        "outputId": "6137f2a9-dee6-40b6-b1a1-03aae14485ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xander decided to go buy some new dog treats.\n",
            "Event: PersonX decided to go buy some new dog treats\n",
            "Preconditions: ['Xander goes to the pet store', 'Xander goes to the store', 'Xander goes to the pet shop', 'Xander buys some dog treats', 'Xander buys dog treats', 'to go to the store', 'to have a dog', 'to go to a store', 'to have a pet', 'to have money', 'to feed the dog', 'to feed the dog', 'to feed his dog', 'to feed his dog', 'to feed their dog']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Xander': {'gets a receipt', 'buys dog treats', 'good', 'eats the treats', 'to feed the dog the treats', 'to feed it', 'to take the dog home', 'satisfied', 'to feed the dog treats', 'happy', \"Xander's dog hates his treats.\", 'to feed the dog', 'excited', 'content'}})\n",
            "None of the dog treats at the pet store looked tasty.\n",
            "Story fails!\n",
            "Xander decided to buy his dog some salmon from the fish market.\n",
            "Event: PersonX decided to buy his dog some salmon from the fish market\n",
            "Preconditions: ['Xander goes to the fish market', 'Xander goes to the grocery store', 'Xander goes to the market', 'Xander feeds the dog salmon', 'Xander feeds the dog', 'to go to the market', 'to go to the store', 'to drive to the market', 'to have a dog', 'to have money', 'to feed his dog', 'to feed the dog', 'to feed their dog', 'to feed his pet', 'to feed it']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Xander': {'Xander feeds their dog', 'to give it to the dog', 'to feed the dog the treats', 'satisfied', 'to feed the dog', 'to give it to his dog', 'eats the treats', 'Xander feeds his dog', 'happy', \"Xander's dog hates his treats.\", 'excited', 'to feed it to the dog', 'to feed it', 'Xander feeds the dog', 'buys dog treats', 'good', 'to take the dog home', 'hungry', 'to feed the dog treats', 'to feed it to his dog', 'gets a receipt', 'eats the salmon', 'content'}})\n",
            "Xander's dog loved the salmon.\n",
            "Event: PersonX dog loved the salmon\n",
            "Preconditions: [\"Xander's takes the salmon home\", \"Xander's feeds the dog salmon\", \"Xander's eats the salmon\", \"Xander's eats salmon\", 'to go to the restaurant', 'to go to the store', 'to go to a restaurant', 'to go to the market', 'to eat the salmon', 'to eat the salmon', 'to have a companion', 'to eat the fish', 'to eat salmon']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Xander': {'Xander feeds their dog', 'to give it to the dog', 'to feed the dog the treats', 'satisfied', 'to feed the dog', 'to give it to his dog', 'eats the treats', 'Xander feeds his dog', 'happy', \"Xander's dog hates his treats.\", 'excited', 'to feed it to the dog', 'to feed it', 'Xander feeds the dog', 'buys dog treats', 'good', 'to take the dog home', 'hungry', 'to feed the dog treats', 'to feed it to his dog', 'gets a receipt', 'eats the salmon', 'content'}, \"Xander's\": {\"Xander's's dog is full\", 'to feed it to the dog', 'to feed it to their dog', 'good', \"Xander's eats the salmon\", \"Xander's's dog is happy\", 'satisfied', \"Xander's eats salmon\", 'to feed the salmon', 'happy', 'to take the salmon home', 'to feed the dog', 'excited', 'content'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 5\n",
        "\n",
        "start = defaultdict(set)\n",
        "start['Franco'] = set([stories[5][0]])\n",
        "runStory(stories[5][1:], start)\n"
      ],
      "metadata": {
        "id": "8VWrx3YLxv37",
        "outputId": "33a8fc45-9aba-45bb-b96b-c00e61358439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Franco decided to follow an old family recipe.\n",
            "Event: PersonX decided to follow an old family recipe\n",
            "Preconditions: ['Franco makes a new recipe', 'Franco buys a recipe book', 'Franco eats the recipe', 'Franco cooks a meal', 'Franco makes a new dish', 'to read the recipe', 'to learn the recipe', 'to know the recipe', 'to have a recipe', 'to be a good cook', 'to follow a family recipe', 'to make a good meal', 'to follow a family tradition', 'to make a good dinner']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Franco': {'to eat the food', 'to eat the meal', 'Franco has never cooked for his family.', 'good', 'Franco eats the recipe', 'Franco cooks a meal', 'Franco makes a meal', 'accomplished', 'to make the recipe', 'satisfied', 'proud', 'to follow the recipe', 'happy', 'learns a new recipe', 'to eat the recipe', 'Franco eats the food'}})\n",
            "Franco's grandma told him anybody could make the recipe.\n",
            "Event: PersonX grandma told him anybody could make the recipe\n",
            "Preconditions: [\"Franco's learns how to cook\", \"Franco's makes the recipe\", \"Franco's makes a new recipe\", \"Franco's learns the recipe\", \"Franco's makes a recipe\", 'to know how to cook', 'to ask for the recipe', 'to know the recipe', 'to have a recipe', 'to be helpful', 'to be encouraging', 'to be nice', 'to teach someone', 'to teach']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Franco': {'to eat the food', 'to eat the meal', 'Franco has never cooked for his family.', 'good', 'Franco eats the recipe', 'Franco cooks a meal', 'Franco makes a meal', 'accomplished', 'to make the recipe', 'satisfied', 'proud', 'to follow the recipe', 'happy', 'learns a new recipe', 'to eat the recipe', 'Franco eats the food'}, \"Franco's\": {'to teach him', \"Franco's learns a new skill\", 'good', 'to teach him the recipe', \"Franco's learns how to cook\", 'to teach them', 'satisfied', 'proud', 'to teach others', 'happy', \"Franco's learns a new recipe\", 'helpful', \"Franco's gets a recipe\", 'to help him learn'}})\n",
            "Franco made a whole meal for his family in one hour.\n",
            "Event: PersonX made a whole meal for his family in one hour\n",
            "Preconditions: ['Franco cooks a meal', 'Franco cooks the meal', 'Franco eats the meal', 'Franco makes dinner', 'to get the ingredients', 'to buy ingredients', 'to have a recipe', 'to get ingredients', 'to cook', 'to feed his family', 'to feed the family', 'to be generous', 'to be helpful', 'to eat']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Franco': {'gets thanked', 'to eat the food', 'to serve the family', 'satisfied', 'to follow the recipe', 'Franco eats the food', 'Franco has never cooked for his family.', 'gets tired', 'Franco is praised', 'Franco cooks a meal', 'to make the recipe', 'proud', 'happy', 'accomplished', 'to eat the recipe', 'Franco eats the recipe', 'Franco makes a meal', 'to serve the food', 'to feed the family', 'Franco is thanked', 'Franco is full', 'to eat the meal', 'good', 'hungry', 'learns a new recipe'}, \"Franco's\": {'to teach him', \"Franco's learns a new skill\", 'good', 'to teach him the recipe', \"Franco's learns how to cook\", 'to teach them', 'satisfied', 'proud', 'to teach others', 'happy', \"Franco's learns a new recipe\", 'helpful', \"Franco's gets a recipe\", 'to help him learn'}})\n",
            "Franco's family all loved the meal.\n",
            "Event: PersonX family all loved the meal\n",
            "Preconditions: [\"Franco's cooks a good meal\", \"Franco's eats the meal\", \"Franco's cooks a good dinner\", \"Franco's eats the food\", 'to cook the meal', 'to prepare the meal', 'to cook a meal', 'to prepare a meal', 'to cook', 'to enjoy the meal', 'to share the meal', 'to be loved', 'to be nice']\n",
            "Validity: True\n",
            "Schema: defaultdict(<class 'set'>, {'Franco': {'gets thanked', 'to eat the food', 'to serve the family', 'satisfied', 'to follow the recipe', 'Franco eats the food', 'Franco has never cooked for his family.', 'gets tired', 'Franco is praised', 'Franco cooks a meal', 'to make the recipe', 'proud', 'happy', 'accomplished', 'to eat the recipe', 'Franco eats the recipe', 'Franco makes a meal', 'to serve the food', 'to feed the family', 'Franco is thanked', 'Franco is full', 'to eat the meal', 'good', 'hungry', 'learns a new recipe'}, \"Franco's\": {'to teach him', 'gets thanked', 'to teach him the recipe', 'smiles', 'satisfied', 'loved', \"Franco's learns a new recipe\", \"Franco's gets a recipe\", 'to help him learn', 'eats the meal', 'proud', 'happy', \"Franco's learns how to cook\", 'to eat more food', 'full', 'to teach others', 'to teach them', 'to eat the meal', \"Franco's learns a new skill\", 'good', 'to eat more', 'helpful', 'to enjoy the meal', 'to share the meal'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Moeba3PR0eMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PC8ocsUWWill"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "111ec73ecef149aaafd98f7ad81f5898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90a79f9dc4614c939f230a2116493dac",
              "IPY_MODEL_b78843a0d4c340aa8d0bfa1101e03070",
              "IPY_MODEL_48b999ba65f34a82a002a1c2da34644d"
            ],
            "layout": "IPY_MODEL_8a38b53f5e66460395c594bfa35f8a90"
          }
        },
        "90a79f9dc4614c939f230a2116493dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1042fe478740abafc82ceb900ea660",
            "placeholder": "​",
            "style": "IPY_MODEL_4d19ac0702dc47e28831258a997692e8",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: "
          }
        },
        "b78843a0d4c340aa8d0bfa1101e03070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba54bfb166b426f819b59f548f926e8",
            "max": 48453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d58a2b66956c4927b53567dd6991a66a",
            "value": 48453
          }
        },
        "48b999ba65f34a82a002a1c2da34644d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d9de39c28c42fab825af1f184c060f",
            "placeholder": "​",
            "style": "IPY_MODEL_6f7215248ac9430f9ae74d2d8826a4e2",
            "value": " 392k/? [00:00&lt;00:00, 6.74MB/s]"
          }
        },
        "8a38b53f5e66460395c594bfa35f8a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1042fe478740abafc82ceb900ea660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d19ac0702dc47e28831258a997692e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ba54bfb166b426f819b59f548f926e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58a2b66956c4927b53567dd6991a66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38d9de39c28c42fab825af1f184c060f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f7215248ac9430f9ae74d2d8826a4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}